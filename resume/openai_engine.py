from django.conf import settings

import openai
from openai import OpenAI

client = OpenAI(api_key=settings.OPENAI_API_KEY)


def send_openai_message(
    user_message: str,
    meta_prompt: str = None,
    model: str = "gpt-4o-mini",
    is_json: bool = False,
    temperature: float = None,
    max_tokens: int = None,
):
    """
    Sends a message to the OpenAI API with a specified system prompt.

    Parameters:
        user_message (str): The content provided by the user to be processed.
        meta_prompt (str): The system prompt to guide the assistant's response style.
                           Defaults to a generic "helpful assistant" if not specified.
        model (str): The OpenAI model to use (default: "gpt-4o-mini").
        is_json (bool): Whether to enforce JSON output format (default: False).
        temperature (float): Sampling temperature. Use 0 for deterministic outputs
                             (e.g. JSON extraction), ~0.7 for creative tasks.
        max_tokens (int): Maximum tokens to generate. Limits response length and
                          reduces latency.

    Returns:
        str: The response content generated by the OpenAI API, or an error message in case of an exception.
    """
    meta_prompt = meta_prompt if meta_prompt else "You are a helpful assistant."

    try:
        kwargs = {
            "model": model,
            "messages": [
                {"role": "system", "content": meta_prompt},
                {"role": "user", "content": user_message}
            ]
        }

        if is_json:
            kwargs["response_format"] = {"type": "json_object"}
        if temperature is not None:
            kwargs["temperature"] = temperature
        if max_tokens is not None:
            kwargs["max_tokens"] = max_tokens

        response = client.chat.completions.create(**kwargs, timeout=90)

        if hasattr(response, 'usage'):
            print(f"[INFO] OpenAI Usage: {response.usage}")

        return response.choices[0].message.content

    except openai.APIError as e:
        return f"OpenAI API returned an API Error: {e}"
    except openai.RateLimitError as e:
        return f"OpenAI API request exceeded rate limit: {e}"
    except Exception as e:
        return f"Error: {str(e)}"


# TODO Convert class based structure
def enhance_resume_experience(user_message: str, language: str = "English"):
    """
    Enhances work experience descriptions to be suitable for a resume in the STAR format.

    Parameters:
        user_message (str): The user's work experience description(s) to be improved.
        language (str): The language to use for enhanced output (default: "English").

    Returns:
        str: The STAR-enhanced, resume-ready work experience description(s).
    """

    meta_prompt = f"""
    Act as a professional resume experience enhancer.
    IMPORTANT: You MUST respond in {language}.
    
    I will provide work experience descriptions. Your task:
    
    1. SPLIT into separate bullet points:
       - If the input contains multiple distinct achievements, responsibilities, or topics, 
         split them into separate lines (one achievement per line).
       - Each line should focus on ONE specific accomplishment or responsibility.
    
    2. ENHANCE each bullet point:
       - Start with a strong action verb (Developed, Implemented, Led, Optimized, etc.)
       - Follow the STAR format implicitly (Situation-Task-Action-Result)
       - Only include metrics if the user explicitly mentioned them. Do NOT fabricate numbers or percentages.
       - Keep each bullet concise (ideally 1-2 lines)
    
    3. OUTPUT FORMAT:
       - Return each bullet point on a separate line
       - No bullet point symbols, just plain text
       - One empty line between each bullet point
       - No numbering
    
    Example Input:
    "Developed backend solutions using Django, collaborated with DevOps on Kubernetes, implemented WebSocket for notifications."
    
    Example Output:
    Developed scalable backend solutions using Django and Django Rest Framework, enabling reliable API services for production workloads

    Collaborated with DevOps team to streamline Kubernetes Helm configurations, accelerating the deployment pipeline

    Implemented WebSocket integration for real-time notification and messaging services, enhancing user engagement
    """.strip()

    return send_openai_message(
        user_message=user_message, meta_prompt=meta_prompt, model="gpt-4o-mini",
        temperature=0.7, max_tokens=1500,
    )


def enhance_project_description(user_message: str, language: str = "English"):
    """
    Enhances project description to be suitable for a resume in the STAR format.

    Parameters:
        user_message (str): The user's project description to be improved.
        language (str): The language to use for enhanced output (default: "English").

    Returns:
        str: The STAR-enhanced, resume-ready project description.
    """

    meta_prompt = f"""
    Act as a professional project description enhancer for resumes.
    IMPORTANT: You MUST respond in {language}.
    
    I will provide project descriptions. Your task:
    
    1. ANALYZE the content:
       - Identify distinct features, achievements, or technical implementations
       - If multiple topics exist, split them into separate statements
    
    2. ENHANCE each point:
       - Start with action verbs (Built, Developed, Designed, Implemented, etc.)
       - Highlight technologies used
       - Only include metrics if the user explicitly mentioned them. Do NOT fabricate numbers or percentages.
       - Keep each point concise and impactful
    
    3. OUTPUT FORMAT:
       - For projects with multiple features: return each on a separate line
       - One empty line between points
       - No bullet points or numbering
       - Focus on technical achievements and real outcomes
    
    Example Input:
    "Built a tool to search for Hiring Managers using ReactJS and Firebase. Over 25000 people have used it."
    
    Example Output:
    Built a Hiring Manager search tool using ReactJS, NodeJS, and Firebase, serving over 25,000 users

    Implemented boolean query system that delivers highly relevant search results for recruiters and job seekers
    """.strip()

    return send_openai_message(
        user_message=user_message, meta_prompt=meta_prompt, model="gpt-4o-mini",
        temperature=0.7, max_tokens=1500,
    )

def extract_resume_data(user_message: str):
    """
    Extracts structured resume data from a given text using OpenAI GPT.

    Parameters:
        user_message (str): The raw text extracted from a resume.

    Returns:
        str: A JSON string containing structured resume data, or a parse error dict as JSON string.
    """

    meta_prompt = """
    Act as a resume parser. I will provide you with raw text extracted from a resume PDF.

    IMPORTANT — Multi-column / garbled text handling:
    The text may come from a multi-column PDF and could be jumbled, interleaved, or out of order.
    Reconstruct the logical reading order before extracting data. Look for contextual clues
    (dates next to company names, job titles near descriptions) to reassemble sections correctly,
    even if the raw text mixes columns together.

    Your task is to extract and structure the data into the following JSON format:

    {
        "language": "detected language of the resume (e.g. English, Turkish, German)",
        "user_info": {
            "full_name": "extracted_full_name",
            "email": "extracted_email",
            "phone": "extracted_phone",
            "address": "extracted_address",
            "linkedin": "extracted_linkedin_url",
            "github": "extracted_github_url",
            "skills": ["extracted_skill1", "extracted_skill2"]
        },
        "experience": [
            {
                "title": "extracted_job_title1",
                "company": "extracted_company1",
                "start_date": "YYYY-MM",
                "end_date": "YYYY-MM",
                "description": ["bullet_point_1", "bullet_point_2", "bullet_point_3"],
                "current_role": true or false
            }
        ],
        "education": [
            {
                "degree": "extracted_degree1",
                "school": "extracted_school1",
                "field_of_study": "extracted_field_of_study1",
                "start_date": "YYYY-MM",
                "end_date": "YYYY-MM"
            }
        ],
        "projects_and_publications": [
            {
                "name": "extracted_project_or_publication_title1",
                "description": "extracted_project_or_publication_description1",
                "link": "extracted_link"
            }
        ]
    }

    For the "experience" section:
    - "description" MUST ALWAYS be a JSON array of strings, one bullet point per element.
      NEVER return description as a plain string. If the original text has a single paragraph,
      split it into an array by newlines or logical sentence boundaries.
    - Each bullet point should be a clear, action-oriented statement.
    - If the start and end dates are not explicitly mentioned for a task or project, inherit them from the main job entry.

    Date normalization rules (apply to ALL date fields):
    - Always output dates in YYYY-MM format.
    - If only a year is given (e.g. "2022"), output "2022-01".
    - If a month name is given (e.g. "March 2022"), convert to "2022-03".
    - If "Present" or "Current", set end_date to null and current_role to true.

    For "education" section:
    - degree should be Bachelor, Master, or PhD.
    - field of study should be Computer Science, Engineering, etc.

    For "projects_and_publications" section:
    - if link is not valid url, leave it empty.

    For "user_info" section:
    - if linkedin and github not valid url, leave it empty.
    - if there linkedin url or github url, urls should be start with https://

    For "language" field:
    - Detect the primary language of the resume content (e.g. "English", "Turkish", "German").
    - Use the full English name of the language.

    Ensure the JSON is well-structured and includes all relevant information.
    If a section is missing in the input text, leave it empty in the JSON.
    """.strip()

    result = send_openai_message(
        user_message=user_message, meta_prompt=meta_prompt, model="gpt-4o-mini",
        is_json=True, temperature=0, max_tokens=6000,
    )

    # Validation: check for empty/corrupted PDF parse failure
    try:
        import json as _json
        parsed = _json.loads(result)
        has_name = bool(parsed.get("user_info", {}).get("full_name", "").strip())
        has_experience = bool(parsed.get("experience"))
        if not has_name and not has_experience:
            return _json.dumps({
                "parse_error": True,
                "message": "Could not extract resume data. Please ensure the PDF contains readable text."
            })
    except (ValueError, TypeError):
        # If result isn't valid JSON at all, it's likely an API error string — pass through
        pass

    return result

def extract_linkedin_resume_data(user_message: str):
    """
    Parses LinkedIn profile data from a PDF file using OpenAI's API.

    Args:
        user_message: The raw text extracted from a LinkedIn PDF.

    Returns:
        str: Parsed data as a JSON string.

    """

    meta_prompt = """
    Act as a LinkedIn profile parser. I will provide you with raw text extracted from a LinkedIn profile PDF.

    IMPORTANT — Multi-column / garbled text handling:
    The text may come from a multi-column PDF and could be jumbled, interleaved, or out of order.
    Reconstruct the logical reading order before extracting data. Look for contextual clues
    (dates next to company names, job titles near descriptions) to reassemble sections correctly.

    Your task is to extract and structure the data into the following JSON format:

    {
    “language”: “detected language of the resume (e.g. English, Turkish, German)”,
    “user_info”: {
        “full_name”: “extracted_full_name”,
        “email”: “extracted_email”,
        “phone”: “extracted_phone”,
        “address”: “extracted_address”,
        “linkedin”: “extracted_linkedin_url”,
        “github”: “extracted_github_url”,
        “skills”: [“extracted_skill1”, “extracted_skill2”]
    },
    “experience”: [
        {
        “title”: “job_title”,
        “company”: “company_name”,
        “start_date”: “YYYY-MM”,
        “end_date”: “YYYY-MM or null if current”,
        “location”: “city, country (if available)”,
        “description”: [“bullet_point_1”, “bullet_point_2”],
        “current_role”: true/false
        }
    ],
    “education”: [
        {
        “school”: “university_name”,
        “degree”: “Bachelor / Master / PhD”,
        “field_of_study”: “field_name”,
        “start_date”: “YYYY-MM”,
        “end_date”: “YYYY-MM”
        }
    ]
    }

    Guidelines:
    - “description” MUST ALWAYS be a JSON array of strings, one bullet point per element.
      NEVER return description as a plain string. If the original text has a single paragraph,
      split it into an array by newlines or logical sentence boundaries.
    - Extract skills and certifications from any relevant sections or lists.
    - For `current_role`, mark as `true` if the person is still working in that position.
    - If any field is missing in the input, set it to null or leave it empty.
    - Remove page numbers or artifacts (e.g., “Page 1 of 3”) from descriptions.

    Date normalization rules (apply to ALL date fields):
    - Always output dates in YYYY-MM format.
    - If only a year is given (e.g. “2022”), output “2022-01”.
    - If a month name is given (e.g. “March 2022”), convert to “2022-03”.
    - If “Present” or “Current”, set end_date to null and current_role to true.

    - If there linkedin url or github url, urls should be start with https://

    For “language” field:
    - Detect the primary language of the resume content (e.g. “English”, “Turkish”, “German”).
    - Use the full English name of the language.

    Ensure the JSON output is well-formed, accurate, and complete.
    """.strip()

    return send_openai_message(
        user_message=user_message, meta_prompt=meta_prompt, model="gpt-4o-mini",
        is_json=True, temperature=0, max_tokens=6000,
    )